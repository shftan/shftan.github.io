---
layout: frontpage
title: Sarah Tan
description: Research Scientist, Responsible AI
keywords: Sarah Tan, responsible AI, machine learning, artificial intelligence, statistics
---

<div class="row-fluid" id="about">
                <div class="span4">
           <img src="picture.png" width = "95%" title="Sarah Tan" alt="Sarah Tan"/>
           <b>Hui Fen (Sarah) Tan</b><br>
         
           <a class="paper" href="https://scholar.google.com/citations?user=_tSKmPYAAAAJ&hl=en">Google Scholar</a><br>

           <a class="paper" href="https://www.linkedin.com/in/shftan/">LinkedIn</a><br>

           <a class="paper" href="https://github.com/shftan">Github</a>
        </div>
        
        <div class="span8">
                <p>I am a researcher interested in AI safety, causal inference, interpretability, and healthcare. Currently, I am a Principal Research Scientist in Responsible AI at Salesforce. I also hold a Visiting Scientist appointment at Cornell University. I co-founded the <a href="https://www.trustworthyml.org/">Trustworthy ML Initiative</a> and am president of <a href="https://www.wiml.org/">Women in Machine Learning (WiML)</a>.</p>   
                  
                  <p>I received my PhD in Statistics from <a href="https://stat.cornell.edu/">Cornell University</a>, where I was advised by <a href="http://faculty.bscb.cornell.edu/~hooker/">Giles Hooker</a> and <a href="https://courses.cit.cornell.edu/mtw1/">Martin Wells</a>, with <a href="https://www.cs.cornell.edu/people/tj/">Thorsten Joachims</a> and <a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich Caruana</a> on my committee.</p> 
                
<p>Previously, I studied at Berkeley and Columbia, and worked in public policy in NYC, including the health department and public hospitals system. I was also a <a href="http://www.dssgfellowship.org/">Data Science for Social Good</a> fellow. I was fortunate to spend summers at Microsoft Research. Towards the end of my PhD studies, I was a visiting student and bioinformatics programmer at <a href="https://epibiostat.ucsf.edu/">UCSF</a> medical school. I joined Facebook after completing my PhD, and worked in Core Data Science before moving to Responsible AI.</p> 
                
        </div>
</div>

<div class="row-fluid" id="contact"><h3>Contact</h3></div>
You can reach me at ht395 AT cornell.edu.

<div class="row-fluid" id="news"><h3>News</h3>
</div>
- 9/24: Gave a guest lecture for the University of Southern California's ENG 499 "Ethics in Engineering Design of AI Systems" class.
- 8/24: Representing Salesforce on a US AI Safety Institute task force.
- 8/24: Co-organizing 2nd edition of [Regulatable ML](https://regulatableml.github.io/) workshop at NeurIPS 2024. Submit your paper!
- 5/24: Did a fireside chat in the University of Colorado Denver's PUAD 6600 "AI for Public Sector Innovation" class.
- 9/23: Was a panelist at Columbia Business School's Challenges in Operationalizing Responsible AI workshop. 
- 1/23: I have been elected president of the [Women in Machine Learning](https://wimlworkshop.org) organization (WiML).
- 1/23: I will be the Tutorial Chair for [FAccT 2023](https://facctconference.org/2023/index.html).
- 9/21: I will be the Diversity & Inclusion Chair for [AISTATS 2022](http://aistats.org/aistats2022/).

For other news, click <a class="paper" href="oldernews.html">here</a>.

<div class="row-fluid" id="code"><h3>Code & Data</h3>
</div>
- [Code](https://github.com/shftan/tree_ensemble_distance) for gradient boosted trees distance proposed in [tree space prototypes paper](https://arxiv.org/abs/1611.07115)
- R package [surfin: (Statistical Inference for Random Forests)](http://shftan.github.io/surfin/)
- [Data and code](https://github.com/shftan/auditblackbox) for [distilling black-box risk scores paper](https://arxiv.org/abs/1710.06169)

<div class="row-fluid" id="publications"><h3>Publications and Preprints</h3>
</div>
<h4>Journal and Conference Papers</h4>
- <a class="paper" href="https://arxiv.org/abs/2410.23252">Evaluating Cultural and Social Awareness of LLM Web Agents</a>
   - H Qiu, AR Fabbri, D Agarwal, KH Huang, Tan, N Peng, CS Wu
   - _NAACL 2025_
   - Also appeared in: _SoCal NLP Symposium 2024_
- <a class="paper" href="https://arxiv.org/abs/2312.04712">Error Discovery By Clustering Influence Embeddings</a>
   - F Wang, J Adebayo, Tan, D Garcia-Olano, N Kokhlikyan
   - _NeurIPS 2023_
   - Also appeared in: _ICLR 2023 Pitfalls of limited data and computation for Trustworthy ML Workshop_ (<span class="highlight">Oral</span>)
- <a class="paper" href="https://arxiv.org/abs/2304.11749">Missing Values and Imputation in Healthcare Data: Can Interpretable Machine Learning Help?</a>
   - Z Chen, Tan, U Chajewska, C Rudin, R Caruana
   - _CHIL 2023_
- <a class="paper" href="https://arxiv.org/abs/1801.08640">Considerations When Learning Additive Explanations for Black-Box Models</a>
   - Tan, G Hooker, P Koch, A Gordo, R Caruana
   - _Machine Learning_ 2023 
   - Also appeared in: _NeurIPS 2018 Machine Learning for Health Workshop_
- <a class="paper" href="https://arxiv.org/abs/2111.03267">Interpretable Personalized Experimentation</a>
   - H Wu, Tan, W Li, M Garrard, A Obeng, D Dimmery, S Singh, H Wang, D Jiang, E Bakshy
   - _KDD 2022_
   - Also appeared in: _Conference on Digital Experimentation 2021_ (<span class="highlight">Oral</span>)
- <a class="paper" href="https://arxiv.org/abs/2006.06466">How Interpretable and Trustworthy are GAMs?</a>
   - CH Chang, Tan, B Lengerich, A Goldenberg, R Caruana
   - _KDD 2021_
- <a class="paper" href="https://arxiv.org/abs/2002.01111">Do I Look Like a Criminal? Examining the Impact of Racial Information on Human Judgement</a>
   - K Mallari, K Inkpen, P Johns, Tan, D Ramesh, E Kamar
   - _CHI 2020_
- <a class="paper" href="https://arxiv.org/abs/1611.07115">Tree Space Prototypes: Another Look at Making Tree Ensembles Interpretable</a>
   - Tan, M Soloviev, G Hooker, M Wells
   - _ACM-IMS FODS 2020_ 
   - Also appeared in: _NIPS 2016 Interpretability Workshop_
   - <a class="resource" href="https://github.com/shftan/tree_ensemble_distance">Code</a>
- <a class="paper" href="http://proceedings.mlr.press/v108/lengerich20a/lengerich20a.pdf">Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models</a>
   - B Lengerich, Tan, CH Chang, G Hooker, R Caruana
   - _AISTATS 2020_
- <a class="paper" href="https://arxiv.org/abs/1810.09092">Axiomatic Interpretability for Multiclass Additive Models</a>
   - X Zhang, Tan, P Koch, Y Lou, U Chajewska, R Caruana
   - _KDD 2019_ (<span class="highlight">Oral</span>)
   - [Video](https://drive.google.com/file/d/14ECmVDOfW0kOBra68ZSHoeSq8nGdePF5/view?usp=sharing)
- <a class="paper" href="https://arxiv.org/abs/1710.06169">Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation</a>
   - Tan, R Caruana, G Hooker, Y Lou
   - _AIES 2018_ (<span class="highlight">Oral</span>)
   - Also appeared in: _NIPS 2017 Interpretability Symposium_ (<span class="highlight">Spotlight</span>), _NIPS 2017 Transparent Machine Learning in Safety Critical Environments Workshop_ (<span class="highlight">Spotlight</span>)
   - Media coverage: [MIT Technology Review](https://www.technologyreview.com/s/609338/new-research-aims-to-solve-the-problem-of-ai-bias-in-black-box-algorithms/), [Politico](https://www.politico.com/agenda/story/2018/02/07/algorithmic-bias-software-recommendations-000631), [Futurism](https://futurism.com/ai-bias-black-box/), [WorkFlow](https://www.servicenow.com/workflow/algorithmic-audit.html) 
   - <a class="resource" href="https://github.com/shftan/auditblackbox">Code and data</a>
- <a class="paper" href="https://www.sciencedirect.com/science/article/pii/S1755436516300755">A Bayesian Evidence Synthesis Approach to Estimate Disease Prevalence in Hard-To-Reach Populations: Hepatitis C in New York City</a>
   - Tan, S Makela, D Heller, K Konty, S Balter, T Zheng, J Stark
   - _Epidemics_ 2018
   - Presented to NYC Health Commissioner. Talk at [NDRI](http://www.ndri.org) 
   - <a class="resource" href="https://www.sciencedirect.com/science/article/pii/S1755436516300755?via%3Dihub#sec0190">Code</a>
- <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0003122415598534">"No Fracking Way!" Documentary Film, Discursive Opportunity, and Local Opposition against Hydraulic Fracturing in the United States, 2010 to 2013</a>
   - I Vasi, E Walker, JS Johnson, Tan 
   - _American Sociological Review_ 2015
   - <span class="highlight">2 Best Paper Awards</span> from American Sociological Association's [CITAMS](https://citams.org/citasa-awards) and [CBSM](http://cbsm-asa.org/awards) sections 
   - Media coverage: [The Guardian](https://www.theguardian.com/environment/2015/sep/02/gasland-hbo-documentary-fracking-opposition), [The Atlantic](https://www.theatlantic.com/entertainment/archive/2017/02/a-common-theme-for-this-years-oscar-nominated-documentaries/517638/), [Pacific Standard](https://psmag.com/environment/a-fracking-effective-film)
   - Press releases: [University of Iowa](http://www.newswise.com/articles/the-power-of-film), [Harmony Institute](https://harmonylabs.org/gasland)
   
<h4>Preprints</h4>
- <a class="paper" href="https://arxiv.org/abs/2406.10290">MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases</a>
   - R Murthy, L Yang, J Tan, T Awalgaonkar, Y Zhou, S Heinecke, S Desai, J Wu, R Xu, Tan, J Zhang, Z Liu, S Kokane, Z Liu, M Zhu, H Wang, C Xiong, S Savarese
   - Under review
- <a class="paper" href="https://arxiv.org/abs/2410.14180">XForecast: Evaluating Natural Language Explanations for Time Series Forecasting</a>
   - T Aksu, C Liu, A Saha, Tan, C Xiong, D Sahoo
   - Under review
- <a class="paper" href="papers/turkercompas.pdf">Investigating Human + Machine Complementarity: A Case Study on Recidivism</a>
   - Tan, J Adebayo, K Inkpen, E Kamar
   - Under review
   - Preliminary version in _NeurIPS 2018 Workshop on Ethical, Social and Governance Issues in AI_ (<span class="highlight">Spotlight</span>)

For older publications and workshop papers, click <a class="paper" href="olderpublications.html">here</a>.

<div class="row-fluid" id="service"><h3>Service</h3>
</div>
- [Women in Machine Learning](https://wimlworkshop.org) organization (WiML) President (2023 - Present), Vice President (2019 - 2020), Director (2018 - 2019, 2020 - 2023)
- Area chair: [ICML](https://icml.cc/), [FAccT](https://facctconference.org/index.html), [CHIL](https://www.chilconference.org/), [Machine Learning for Health Symposium](https://ml4health.github.io), [Algorithmic Fairness through the Lens of Causality and Privacy](https://www.afciworkshop.org/), [Algorithms Towards Ethical and Privacy Challenges in Social Media Recommendation System](https://sites.google.com/view/aesm2022/home) 
- Reviewer:
  - Conferences: NeurIPS, ICML, ICLR, AISTATS, AIES, KDD, AAAI, WWW, HCOMP
  - Journals: JMLR, TMLR, JAIR, Nature, Machine Learning, TPAMI, TIST, Journal of Biomedical and Health Informatics, IEEE Transactions on Emerging Topics in Computational Intelligence
  - Workshops: [Fair ML for Health](https://www.fairmlforhealth.com/), [Human-Centric Machine Learning](https://sites.google.com/view/hcml-2019), [Machine Learning for Health](https://ml4health.github.io/2019/), [Human In the Loop Learning](https://sites.google.com/view/hill2019/home), [Safe ML](https://sites.google.com/view/safeml-iclr2019/home), [Computer Vision for Agriculture](https://www.cv4gc.org/cv4a2020/), [Algorithmic Fairness through the Lens of Causality and Interpretability](https://www.afciworkshop.org/), [AI for Public Health Workshop](https://aiforpublichealth.github.io/), [Human in the Loop Learning](https://www.icml-hill.com/), [Algorithmic Fairness through the Lens of Causality and Robustness](https://www.afciworkshop.org/) 
  - Programs: <a href="http://www.dssgfellowship.org/">Data Science for Social Good</a>
- Co-organizer:
  - NeurIPS 2023 and 2024 Workshops ["Regulatable ML"](https://regulatableml.github.io/) (together with Himabindu Lakkaraju, Jiaqi Ma, Chirag Agarwal)
  - Tutorial Chair, [FAccT 2023](https://facctconference.org/2023/) (together with Sina Fazelpour, Angela Zhou)
  - Diversity & Inclusion Chair, [AISTATS 2022](http://aistats.org/aistats2022/) (together with Pablo Samuel Castro)
  - [Trustworthy ML Initiative](https://www.trustworthyml.org/) (together with Himabindu Lakkaraju, Sara Hooker, Subhabrata Majumdar, Chhavi Yadav, Chirag Agarwal, Jaydeep Borkar, Marta Lemanczyk, Haohan Wang)
  - ICLR 2019 Workshop [“Debugging Machine Learning Models”](https://iclr.cc/Conferences/2019/Schedule?showEvent=628) (together with Himabindu Lakkaraju, Julius Adebayo, Jacob Steinhardt, D. Sculley, Rich Caruana) 
  - Invited Session ["New Advances in Causal Inference for Longitudinal and Survival Data"](http://ww2.amstat.org/meetings/ichps/2018/onlineprogram/Program.cfm) at International Conference on Health Policy Statistics (ICHPS) 2018 (together with Michael Elliott and James O'Malley)  
  - Topic-Contributed Session ["Statistics for Social Good"](http://shftan.github.io/jsmsocialgood/) at JSM 2016 (together with Rayid Ghani and Hadley Wickham
  - [2016 WiML Workshop](https://wimlworkshop.org/2016/) (together with Diana Cai, Deborah Hanus, Isabel Valera, Rose Yu). WiML Workshop has grown tremendously, and the year I organized, it had 600 attendees and 200 posters. I am most proud of the mentoring roundtables format we expanded that year, with [50 roundtables on research and career topics](https://wimlworkshop.org/2016/program/#1480549898816-ca283fe3-29b6) bringing together our attendees and experts in close conversation
- Mentor:
  - Reviewing: [Machine Learning for Health Workshop](https://ml4health.github.io/2020/) 
  - Submission: [AI for Public Health Workshop](https://aiforpublichealth.github.io/)
  - Project: [UCSF's AI4ALL program](http://ai4all.ucsf.edu/)
  - Research: Causal Inference research roundtable at 2021 WiML Workshop, Trustworthy ML at 2023 WiML Workshop
  - Seeking funding: [2018](https://wimlworkshop.org/2018/program/), [2019](https://wimlworkshop.org/2019/program/), [2020](https://wimlworkshop.org/neurips2020/program/) WiML Workshop
- Student representative, [ICHPS 2018](http://ww2.amstat.org/meetings/ichps/2018/) Scientific Committee
- **Cornell internal**: I was president of the [Statistics Graduate Society](https://stat.cornell.edu/about-us/sgs) and co-organized (together with Ashudeep Singh) the [Cornell Machine Learning reading group](http://wiki.cs.cornell.edu/index.php?title=Machine_Learning_Discussion_Group)

<div class="row-fluid"><h3>Miscellaneous</h3>
</div>
- I played piano and (bad) ukulele in an Indian fusion carnatic band. We have some videos [here](https://www.youtube.com/playlist?list=PLXf9tYVf-PxM6ESEflnJ8_Oow-j66CgYt)
