---
layout: frontpage
title: Sarah Tan
description: Research Scientist
keywords: Sarah Tan, machine learning, artificial intelligence, statistics
---

<div class="row-fluid" id="about">
                <div class="span4">
           <img src="picture.png" width = "95%" title="Sarah Tan" alt="Sarah Tan"/>
           <b>Hui Fen (Sarah) Tan</b><br>
         
           <a class="paper" href="https://scholar.google.com/citations?user=_tSKmPYAAAAJ&hl=en">Google Scholar</a><br>

           <a class="paper" href="https://www.linkedin.com/in/shftan/">LinkedIn</a><br>

           <a class="paper" href="https://github.com/shftan">Github</a>
        </div>
        
        <div class="span8">
                <p>I am a researcher interested in AI safety, causal inference, interpretability, and healthcare. Currently, I am a Principal Research Scientist in Responsible AI at Salesforce. I also hold a Visiting Scientist appointment at Cornell University.</p> 
                  
                  <p>I received my PhD in Statistics from <a href="https://stat.cornell.edu/">Cornell University</a>, where I was advised by <a href="http://faculty.bscb.cornell.edu/~hooker/">Giles Hooker</a> and <a href="https://courses.cit.cornell.edu/mtw1/">Martin Wells</a>, with <a href="https://www.cs.cornell.edu/people/tj/">Thorsten Joachims</a> and <a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich Caruana</a> on my committee.</p> 
                
<p>Previously, I studied at Berkeley and Columbia, and worked in public policy in NYC, including the health department and public hospitals system. I was fortunate to spend summers at Microsoft Research. Towards the end of my PhD studies, I was a visiting student and bioinformatics programmer at <a href="https://epibiostat.ucsf.edu/">UCSF</a> medical school. I joined Facebook after completing my PhD, and worked in Core Data Science before moving to Responsible AI. Before grad school, I was a data scientist (part of the founding team) at an NLP startup.</p> 

</div>
</div>
                
<div class="row-fluid" id="contact"><h3>Contact</h3></div>
You can reach me at ht395 AT cornell.edu.

<div class="row-fluid" id="news"><h3>News</h3>
</div>
- 9/24: Gave a guest lecture for the University of Southern California's ENG 499 "Ethics in Engineering Design of AI Systems" class.
- 8/24: Representing Salesforce on a US AI Safety Institute task force.
- 8/24: Co-organizing 2nd edition of [Regulatable ML](https://regulatableml.github.io/) workshop at NeurIPS 2024. Submit your paper!
- 5/24: Did a fireside chat in the University of Colorado Denver's PUAD 6600 "AI for Public Sector Innovation" class.
- 9/23: Was a panelist at Columbia Business School's Challenges in Operationalizing Responsible AI workshop. 
- 1/23: I will be the Tutorial Chair for [FAccT 2023](https://facctconference.org/2023/index.html).

For other news, click <a class="paper" href="oldernews.html">here</a>.

<div class="row-fluid" id="code"><h3>Code & Data</h3>
</div>
- [Code](https://github.com/shftan/tree_ensemble_distance) for gradient boosted trees distance proposed in [tree space prototypes paper](https://arxiv.org/abs/1611.07115)
- R package [surfin: (Statistical Inference for Random Forests)](http://shftan.github.io/surfin/)
- [Data and code](https://github.com/shftan/auditblackbox) for [distilling black-box risk scores paper](https://arxiv.org/abs/1710.06169)

<div class="row-fluid" id="publications"><h3>Publications and Preprints</h3>
</div>
<h4>Journal and Conference Papers</h4>
- <a class="paper" href="https://arxiv.org/abs/2410.23252">Evaluating Cultural and Social Awareness of LLM Web Agents</a>
   - H Qiu, AR Fabbri, D Agarwal, KH Huang, Tan, N Peng, CS Wu
   - _NAACL 2025_
   - Also appeared in: _SoCal NLP Symposium 2024_ and _C3NLP 2025 Workshop_
- <a class="paper" href="https://arxiv.org/abs/2312.04712">Error Discovery By Clustering Influence Embeddings</a>
   - F Wang, J Adebayo, Tan, D Garcia-Olano, N Kokhlikyan
   - _NeurIPS 2023_
   - Also appeared in: _ICLR 2023 Pitfalls of limited data and computation for Trustworthy ML Workshop_ (<span class="highlight">Oral</span>)
- <a class="paper" href="https://arxiv.org/abs/2304.11749">Missing Values and Imputation in Healthcare Data: Can Interpretable Machine Learning Help?</a>
   - Z Chen, Tan, U Chajewska, C Rudin, R Caruana
   - _CHIL 2023_
- <a class="paper" href="https://arxiv.org/abs/1801.08640">Considerations When Learning Additive Explanations for Black-Box Models</a>
   - Tan, G Hooker, P Koch, A Gordo, R Caruana
   - _Machine Learning_ 2023 
   - Also appeared in: _NeurIPS 2018 Machine Learning for Health Workshop_
- <a class="paper" href="https://arxiv.org/abs/2111.03267">Interpretable Personalized Experimentation</a>
   - H Wu, Tan, W Li, M Garrard, A Obeng, D Dimmery, S Singh, H Wang, D Jiang, E Bakshy
   - _KDD 2022_
   - Also appeared in: _Conference on Digital Experimentation 2021_ (<span class="highlight">Oral</span>)
- <a class="paper" href="https://arxiv.org/abs/2006.06466">How Interpretable and Trustworthy are GAMs?</a>
   - CH Chang, Tan, B Lengerich, A Goldenberg, R Caruana
   - _KDD 2021_
- <a class="paper" href="https://arxiv.org/abs/2002.01111">Do I Look Like a Criminal? Examining the Impact of Racial Information on Human Judgement</a>
   - K Mallari, K Inkpen, P Johns, Tan, D Ramesh, E Kamar
   - _CHI 2020_
- <a class="paper" href="https://arxiv.org/abs/1611.07115">Tree Space Prototypes: Another Look at Making Tree Ensembles Interpretable</a>
   - Tan, M Soloviev, G Hooker, M Wells
   - _ACM-IMS FODS 2020_ 
   - Also appeared in: _NIPS 2016 Interpretability Workshop_
   - <a class="resource" href="https://github.com/shftan/tree_ensemble_distance">Code</a>
- <a class="paper" href="http://proceedings.mlr.press/v108/lengerich20a/lengerich20a.pdf">Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models</a>
   - B Lengerich, Tan, CH Chang, G Hooker, R Caruana
   - _AISTATS 2020_
- <a class="paper" href="https://arxiv.org/abs/1810.09092">Axiomatic Interpretability for Multiclass Additive Models</a>
   - X Zhang, Tan, P Koch, Y Lou, U Chajewska, R Caruana
   - _KDD 2019_ (<span class="highlight">Oral</span>)
   - [Video](https://drive.google.com/file/d/14ECmVDOfW0kOBra68ZSHoeSq8nGdePF5/view?usp=sharing)
- <a class="paper" href="https://arxiv.org/abs/1710.06169">Distill-and-Compare: Auditing Black-Box Models Using Transparent Model Distillation</a>
   - Tan, R Caruana, G Hooker, Y Lou
   - _AIES 2018_ (<span class="highlight">Oral</span>)
   - Also appeared in: _NIPS 2017 Interpretability Symposium_ (<span class="highlight">Spotlight</span>), _NIPS 2017 Transparent Machine Learning in Safety Critical Environments Workshop_ (<span class="highlight">Spotlight</span>)
   - Media coverage: [MIT Technology Review](https://www.technologyreview.com/s/609338/new-research-aims-to-solve-the-problem-of-ai-bias-in-black-box-algorithms/), [Politico](https://www.politico.com/agenda/story/2018/02/07/algorithmic-bias-software-recommendations-000631), [Futurism](https://futurism.com/ai-bias-black-box/), [WorkFlow](https://www.servicenow.com/workflow/algorithmic-audit.html) 
   - <a class="resource" href="https://github.com/shftan/auditblackbox">Code and data</a>
- <a class="paper" href="https://www.sciencedirect.com/science/article/pii/S1755436516300755">A Bayesian Evidence Synthesis Approach to Estimate Disease Prevalence in Hard-To-Reach Populations: Hepatitis C in New York City</a>
   - Tan, S Makela, D Heller, K Konty, S Balter, T Zheng, J Stark
   - _Epidemics_ 2018
   - Presented to NYC Health Commissioner. Talk at [NDRI](http://www.ndri.org) 
   - <a class="resource" href="https://www.sciencedirect.com/science/article/pii/S1755436516300755?via%3Dihub#sec0190">Code</a>
- <a class="paper" href="http://journals.sagepub.com/doi/abs/10.1177/0003122415598534">"No Fracking Way!" Documentary Film, Discursive Opportunity, and Local Opposition against Hydraulic Fracturing in the United States, 2010 to 2013</a>
   - I Vasi, E Walker, JS Johnson, Tan 
   - _American Sociological Review_ 2015
   - <span class="highlight">2 Best Paper Awards</span> from American Sociological Association's [CITAMS](https://citams.org/citasa-awards) and [CBSM](http://cbsm-asa.org/awards) sections 
   - Media coverage: [The Guardian](https://www.theguardian.com/environment/2015/sep/02/gasland-hbo-documentary-fracking-opposition), [The Atlantic](https://www.theatlantic.com/entertainment/archive/2017/02/a-common-theme-for-this-years-oscar-nominated-documentaries/517638/), [Pacific Standard](https://psmag.com/environment/a-fracking-effective-film)
   - Press releases: [University of Iowa](http://www.newswise.com/articles/the-power-of-film), [Harmony Institute](https://harmonylabs.org/gasland)
   
<h4>Preprints</h4>
- <a class="paper" href="https://arxiv.org/abs/2410.15471">Generative Models, Humans, Predictive Models: Who Is Worse at High-Stakes Decision Making?</a>
   - K Mallari, J Adebayo, K Inkpen, MT Wells, A Gordo, Tan
   - Under review
- <a class="paper" href="https://arxiv.org/abs/2406.10290">MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases</a>
   - R Murthy, L Yang, J Tan, T Awalgaonkar, Y Zhou, S Heinecke, S Desai, J Wu, R Xu, Tan, J Zhang, Z Liu, S Kokane, Z Liu, M Zhu, H Wang, C Xiong, S Savarese
   - Under review
- <a class="paper" href="https://arxiv.org/abs/2410.14180">XForecast: Evaluating Natural Language Explanations for Time Series Forecasting</a>
   - T Aksu, C Liu, A Saha, Tan, C Xiong, D Sahoo
   - Under review

For older publications and workshop papers, click <a class="paper" href="olderpublications.html">here</a>.

<h4>Service</h4>
- Area Chair, NeurIPS 2025
- Area Chair, FAccT 2023-2025
- Area Chair, CHIL 2024-2025
- Area Chair, Machine Learning for Health Symposium 2020-2023
